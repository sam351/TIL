{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from konlpy.tag import Twitter\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load & Parse(Preprocess) text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n제5편 빛 속으로!\\n1장 대결(對決)\\n상의와 상근이가 차부에 도착했을 때 모자를 삐딱하게 쓴 천일이가 차표를 끊어놓고 기다리는 참이었다. 그는 표를 건네주면서 \"짐 이리 주라.\"'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('konlpy/BEXX0014.txt', encoding='utf16') as fp:\n",
    "    soup = BeautifulSoup(fp, features='html.parser')\n",
    "    pass\n",
    "\n",
    "body = soup.select_one('text > body')\n",
    "text = body.get_text()\n",
    "\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> total no of lines : 5831\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\Anaconda3\\envs\\py36\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> parsed result - line 1 : \n",
      ">>> parsed result - line 1001 : 석 이 단 하다 번 상현 앞 기화 얘기 하다 적 없다 그것 물론 상현 위 하다 아니다 석 이 자기 자신 위해 말 싶다 않다 일 이다 아니다 덧 없다 자기 사랑 위 하다 말 싶다 않다 것\n",
      ">>> parsed result - line 2001 : 그런데 어떻다 사람 이 것 쟁 받다 얘기 큰일 하나 끝내다 나다 설움 왈칵 솟다 하다 왜 그렇다 요\n",
      ">>> parsed result - line 3001 : 형님 서울 한번 다녀가다 벌써 세 번 편지 오다\n",
      ">>> parsed result - line 4001 : 쓸데없다 말 선생 질 만족하다 아니다 재취 댁 시집가다 궁리 하든\n",
      ">>> parsed result - line 5001 : 그야 당연하다\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['', '제 5 편 빛 속', '1 장 대결 對決']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = text.split('\\n')\n",
    "print(f'>>> total no of lines : {len(lines)}\\n')\n",
    "\n",
    "twitter = Twitter()\n",
    "\n",
    "parsed_lines = []\n",
    "for idx, line in enumerate(lines):\n",
    "    tmp_pos_list = twitter.pos(line, norm=True, stem=True)\n",
    "    \n",
    "    r_line = []\n",
    "    for word in tmp_pos_list:\n",
    "        if word[1] not in ['Josa', 'Punctuation', 'Eomi']:\n",
    "            r_line.append(word[0])\n",
    "        pass\n",
    "    \n",
    "    r_string = ' '.join(r_line).strip()\n",
    "    parsed_lines.append( r_string )\n",
    "    \n",
    "    if idx%1000==0:\n",
    "        print( f'>>> parsed result - line {idx+1} : {r_string}' )\n",
    "    pass\n",
    "\n",
    "parsed_lines[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Save the parsed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result into a wakati file\n",
    "f_name = '200204_toji.wakati'\n",
    "with open(f_name, 'w', encoding='utf8') as fp:\n",
    "    fp.write( '\\n'.join(parsed_lines) )\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate & save word-vector matrix using word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "data = word2vec.LineSentence(f_name)\n",
    "model = word2vec.Word2Vec(data, size=200, window=10, hs=1, min_count=2, sg=1)\n",
    "model.save(\"200204_toji.model\")\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check similar word pair using generated word-vector matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('둘', 0.8884906768798828),\n",
       " ('천도', 0.8749135136604309),\n",
       " ('높다', 0.8740280866622925),\n",
       " ('저승', 0.8483615517616272),\n",
       " ('농사', 0.847848653793335),\n",
       " ('얼다', 0.8475387096405029),\n",
       " ('보태', 0.8426076769828796),\n",
       " ('세상만사', 0.841936469078064),\n",
       " ('지지리', 0.8410280346870422),\n",
       " ('뫼셔', 0.8404742479324341)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = word2vec.Word2Vec.load(\"200204_toji.model\")\n",
    "model.most_similar(positive=[\"땅\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

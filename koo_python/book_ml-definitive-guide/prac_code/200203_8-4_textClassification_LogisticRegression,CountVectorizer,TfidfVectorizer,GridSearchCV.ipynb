{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text-classification using Count-vectorized Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Prepare data (20 Newsgroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "train_news = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), random_state=156)\n",
    "X_train = train_news.data\n",
    "y_train = train_news.target\n",
    "\n",
    "test_news = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), random_state=156)\n",
    "X_test = test_news.data\n",
    "y_test = test_news.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> size of train : 11314  |  size of test : 7532\n",
      "\n",
      "\n",
      ".. _20newsgroups_dataset:\n",
      "\n",
      "The 20 newsgroups text dataset\n",
      "------------------------------\n",
      "\n",
      "The 20 newsgroups dataset comprises around 18000 newsgroups posts on\n",
      "20 topics split in two subsets: one for training (or development)\n",
      "and the other one for testing (or for performance evaluation). The split\n",
      "between the train and test set is based upon a messages posted before\n",
      "and after a specific date.\n",
      "\n",
      "This module contains two loaders. The first one,\n",
      ":func:`sklearn.datasets.fetch_20newsgroups`,\n",
      "returns a list of the raw texts that can be fed to text feature\n",
      "extractors such as :class:`sklearn.feature_extraction.text.CountVectorizer`\n",
      "with custom parameters so as to extract feature vectors.\n",
      "The second one, :func:`sklearn.datasets.fetch_20newsgroups_vectorized`,\n",
      "returns ready-to-use features, i.e., it is not necessary to use a feature\n",
      "extractor.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    =================   ==========\n",
      "    Classes                     20\n",
      "    Samples total            18846\n",
      "    Dimensionality               1\n",
      "    Features                  text\n",
      "    =================   =====\n",
      "\n",
      ">>> names of Classes : \n",
      " ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(f'>>> size of train : {len(X_train)}  |  size of test : {len(X_test)}\\n\\n')\n",
    "print(train_news.DESCR[:1080])\n",
    "print('\\n>>> names of Classes : \\n', train_news.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Topic : alt.atheism\n",
      "\n",
      "\n",
      "What I did NOT get with my drive (CD300i) is the System Install CD you\n",
      "listed as #1.  Any ideas about how I can get one?  I bought my IIvx 8/120\n",
      "from Direct Express in Chicago (no complaints at all -- good price & good\n",
      "service).\n",
      "\n",
      "BTW, I've heard that the System Install CD can be used to boot the mac;\n",
      "however, my drive will NOT accept a CD caddy is the machine is off.  How can\n",
      "you boot with it then?\n",
      "\n",
      "--Dave\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'>>> Topic : {train_news.target_names[0]}')\n",
    "print(train_news.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Vectorize data (using CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 101631)\n",
      "(7532, 101631)\n"
     ]
    }
   ],
   "source": [
    "cnt_vect = CountVectorizer()\n",
    "cnt_vect.fit(X_train, y_train)\n",
    "\n",
    "# Vectorizing X_train & X_test\n",
    "X_train_cnt_vect = cnt_vect.transform(X_train)\n",
    "X_test_cnt_vect = cnt_vect.transform(X_test)\n",
    "\n",
    "print(X_train_cnt_vect.shape)\n",
    "print(X_test_cnt_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Generate model (using Logistic Regression) & Evaluate (using accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4 11  2 ...  6 17  9]\n",
      "\n",
      "accuracy_score of Countvectorized Logistic Regression : 0.616\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit( X_train_cnt_vect, y_train )\n",
    "pred = lr_clf.predict(X_test_cnt_vect)\n",
    "\n",
    "print(pred)\n",
    "print()\n",
    "print(f'accuracy_score of Countvectorized Logistic Regression : {accuracy_score(y_test, pred):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text-classification using TF-IDF-vectorized Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Prepare data (20 Newsgroups) - same data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Vectorize data (using TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 101631) (7532, 101631)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "print(X_train_tfidf_vect.shape, X_test_tfidf_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Generate model (using Logistic Regression) & Evaluate (using accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  1  1 ...  6 17  9]\n",
      "\n",
      "accuracy_score of TF-IDF-vectorized Logistic Regression : 0.678\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit( X_train_tfidf_vect, y_train )\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print(pred)\n",
    "print()\n",
    "print(f'accuracy_score of TF-IDF-vectorized Logistic Regression : {accuracy_score(y_test, pred):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text-classification using TF-IDF-vectorized Logistic Regression\n",
    "#### ( + Parameter tunning - stopwords, n-gram )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) stop_words='english', ngram_range=(1,3), max_df=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of vectorized trand & test : (11314, 1971091) (7532, 1971091)\n",
      "\n",
      "predicted labels : [ 4 11  1 ...  6 17  7]\n",
      "\n",
      "accuracy_score of TF-IDF-vectorized Logistic Regression : 0.687\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer( stop_words='english', ngram_range=(1,3), max_df=300 )\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "print('shape of vectorized trand & test :', X_train_tfidf_vect.shape, X_test_tfidf_vect.shape)\n",
    "print()\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit( X_train_tfidf_vect, y_train )\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('predicted labels :', pred)\n",
    "print()\n",
    "print(f'accuracy_score of TF-IDF-vectorized Logistic Regression : {accuracy_score(y_test, pred):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) stop_words='english', ngram_range=(1,2), max_df=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of vectorized trand & test : (11314, 943453) (7532, 943453)\n",
      "\n",
      "predicted labels : [ 4 11  1 ...  6 17  7]\n",
      "\n",
      "accuracy_score of TF-IDF-vectorized Logistic Regression : 0.690\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer( stop_words='english', ngram_range=(1,2), max_df=300 )\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "print('shape of vectorized trand & test :', X_train_tfidf_vect.shape, X_test_tfidf_vect.shape)\n",
    "print()\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit( X_train_tfidf_vect, y_train )\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('predicted labels :', pred)\n",
    "print()\n",
    "print(f'accuracy_score of TF-IDF-vectorized Logistic Regression : {accuracy_score(y_test, pred):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Parameter tunning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  5.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best C parameter : {'C': 15}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param = { 'C':[0.01, 0.1, 1, 5, 10, 15, 20] }\n",
    "grid_cv_lr = GridSearchCV(estimator=lr_clf , param_grid=param, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_cv_lr.fit( X_train_tfidf_vect, y_train )\n",
    "\n",
    "print('best C parameter :', grid_cv_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted labels : [ 3 11  1 ...  7 17  7]\n",
      "\n",
      "accuracy_score of TF-IDF-vectorized Logistic Regression (with local best C) : 0.705\n"
     ]
    }
   ],
   "source": [
    "pred = grid_cv_lr.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('predicted labels :', pred)\n",
    "print()\n",
    "print(f'accuracy_score of TF-IDF-vectorized Logistic Regression (with local best C) : {accuracy_score(y_test, pred):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

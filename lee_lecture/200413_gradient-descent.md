# 5차시. 머신러닝과 경사하강법



## - 머신러닝의 학습방식

- 머신러닝이란, 데이터를 설명하는 모델 등을 찾는 것
  - ‘모델’은 모수적 방식에서는 함수, 비모수적 방식에서는 규칙이 됨
  - 머신 : 함수 또는 규칙, 러닝 : 변화
- 머신러닝의 목적은, ‘일반화된 모델을 생성’하는 것
  - 일반화된 모델 : 알려지지 않은 데이터도 잘 예측하는 모델
  - 과거의 데이터를 사용해, 알려지지 않은 미래 데이터의 예측/분류를 잘 해야 함
- 구체적인 학습 방식은, 함수를 데이터에 최적화하는 것
  - 예측 값과 실제 데이터 값 사이의 차이(Loss, Cost)를 최소화하는 방식
  - 오차(Loss, Cost) 함수는 일반적으로 MSE를 많이 사용
  - MSE는 W와 Loss의 2차함수이므로, 결국 모델 학습은 2차함수의 최소값이 되는 W를 찾는 것
- 대표적인 최적화 방법 : 경사하강법(Gradient Descent), 대입법 등



## - 경사하강법(Grdient Descent)

- 일반적인 오차함수는 MSE므로, 모델 최적화는 2차함수가 최소값을 갖는 지점을 찾는 문제임
- 경사하강법은 현재 W에 대한 Loss 함수의 미분값(2차함수의 기울기/순간변화율)을 현재 W에서 빼줌으로써 점차 최소값 지점으로 이동하는 방법
- 경사하강법의 문제 : 데이터에 너무 최적화되어 과적합(overfitting) 문제에 취약
  - 머신러닝의 목적은 일반화이므로 이는 본 목적과 상충되는 문제
  - 대안 1. 더 많은 데이터를 학습시키기
  - 대안 2. Loss 함수를 변경해 Loss값을 강제로 키우기(모델 성능을 강제로 약화) 


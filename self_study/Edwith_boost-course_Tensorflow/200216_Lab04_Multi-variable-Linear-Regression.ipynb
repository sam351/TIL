{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Example (2 variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :    1  |  W1 : -4.160  |  W2 :  1.108  |  b :  -6.096  |  cost : 335.281\n",
      "epoch :  101  |  W1 :  0.695  |  W2 :  1.874  |  b :  -4.437  |  cost :  18.959\n",
      "epoch :  201  |  W1 :  1.724  |  W2 :  2.076  |  b :  -3.964  |  cost :   3.445\n",
      "epoch :  301  |  W1 :  1.922  |  W2 :  2.118  |  b :  -3.764  |  cost :   2.525\n",
      "epoch :  401  |  W1 :  1.940  |  W2 :  2.112  |  b :  -3.631  |  cost :   2.337\n",
      "epoch :  501  |  W1 :  1.922  |  W2 :  2.088  |  b :  -3.516  |  cost :   2.196\n",
      "epoch :  601  |  W1 :  1.896  |  W2 :  2.060  |  b :  -3.408  |  cost :   2.066\n",
      "epoch :  701  |  W1 :  1.869  |  W2 :  2.030  |  b :  -3.305  |  cost :   1.944\n",
      "epoch :  801  |  W1 :  1.843  |  W2 :  1.999  |  b :  -3.206  |  cost :   1.829\n",
      "epoch :  901  |  W1 :  1.817  |  W2 :  1.970  |  b :  -3.109  |  cost :   1.720\n",
      "epoch : 1001  |  W1 :  1.793  |  W2 :  1.941  |  b :  -3.016  |  cost :   1.618\n",
      ">>> training time :  5.9153382778167725\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "x1_data = [1, 0, 3, 0, 5]\n",
    "x2_data = [0, 2, 0, 4, 0]\n",
    "y_data = [1, 2, 3, 4, 5]\n",
    "\n",
    "W1 = tf.Variable( tf.random.uniform((1,), -10, 10) )\n",
    "W2 = tf.Variable( tf.random.uniform((1,), -10, 10) )\n",
    "b = tf.Variable( tf.random.uniform((1,), -10, 10) )\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "for i in range(1000+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = tf.multiply(W1, x1_data) + tf.multiply(W2, x2_data) + b\n",
    "        cost = tf.reduce_mean(tf.square(tf.subtract(hypothesis, y_data)))\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        print(f'epoch :{i+1:5}  |  W1 :{W1.numpy()[0]:7.3f}  |  W2 :{W2.numpy()[0]:7.3f}  | ',\n",
    "              f'b : {b.numpy()[0]:7.3f}  |  cost : {cost:7.3f}')\n",
    "    \n",
    "    W1_grad, W2_grad, b_grad = tape.gradient(cost, [W1, W2, b])\n",
    "    W1.assign_sub( tf.multiply(learning_rate, W1_grad) )\n",
    "    W2.assign_sub( tf.multiply(learning_rate, W2_grad) )\n",
    "    b.assign_sub( tf.multiply(learning_rate, b_grad) )\n",
    "    pass\n",
    "\n",
    "finish = time.time()\n",
    "print('>>> training time : ', finish-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Example (2 variables with Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 epoch  |   -0.650  |   -0.364  |   -0.973  |  cost :  36.404\n",
      "  101 epoch  |    0.701  |    0.482  |   -0.351  |  cost :   2.640\n",
      "  201 epoch  |    0.971  |    0.807  |   -0.175  |  cost :   0.285\n",
      "  301 epoch  |    1.019  |    0.936  |   -0.119  |  cost :   0.043\n",
      "  401 epoch  |    1.025  |    0.989  |   -0.098  |  cost :   0.008\n",
      "  501 epoch  |    1.024  |    1.010  |   -0.088  |  cost :   0.002\n",
      "  601 epoch  |    1.022  |    1.019  |   -0.083  |  cost :   0.001\n",
      "  701 epoch  |    1.021  |    1.022  |   -0.080  |  cost :   0.001\n",
      "  801 epoch  |    1.020  |    1.023  |   -0.077  |  cost :   0.001\n",
      "  901 epoch  |    1.020  |    1.023  |   -0.074  |  cost :   0.001\n",
      " 1001 epoch  |    1.019  |    1.022  |   -0.072  |  cost :   0.001\n",
      ">>> training time :  6.2733588218688965\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "x_data = [\n",
    "    [1., 0., 3., 0., 5.],\n",
    "    [0., 2., 0., 4., 0.]\n",
    "]\n",
    "y_data = [1, 2, 3, 4, 5]\n",
    "\n",
    "W = tf.Variable(tf.random.uniform((1, 2), -1, 1))\n",
    "b = tf.Variable(tf.random.uniform((1,), -1, 1))\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "for i in range(1000+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = tf.matmul(W, x_data) + b\n",
    "        cost = tf.reduce_mean(tf.square(tf.subtract(hypothesis, y_data)))\n",
    "        pass\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        print(f'{i+1:5} epoch  |  {W.numpy()[0][0]:7.3f}  |  {W.numpy()[0][1]:7.3f}',\n",
    "              f' |  {b.numpy()[0]:7.3f}  |  cost : {cost:7.3f}')\n",
    "    \n",
    "    W_grad, b_grad = tape.gradient( cost, [W, b] )\n",
    "    W.assign_sub(learning_rate * W_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "finish = time.time()\n",
    "print('>>> training time : ', finish-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis without b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 epoch  |   -0.205  |    0.332  |   -0.698  |  cost :  16.020\n",
      "  101 epoch  |    0.198  |    0.822  |    0.230  |  cost :   2.141\n",
      "  201 epoch  |    0.322  |    0.901  |    0.609  |  cost :   0.367\n",
      "  301 epoch  |    0.359  |    0.908  |    0.767  |  cost :   0.085\n",
      "  401 epoch  |    0.366  |    0.907  |    0.835  |  cost :   0.036\n",
      "  501 epoch  |    0.362  |    0.906  |    0.866  |  cost :   0.026\n",
      "  601 epoch  |    0.354  |    0.908  |    0.881  |  cost :   0.023\n",
      "  701 epoch  |    0.345  |    0.910  |    0.889  |  cost :   0.021\n",
      "  801 epoch  |    0.335  |    0.912  |    0.894  |  cost :   0.020\n",
      "  901 epoch  |    0.325  |    0.915  |    0.898  |  cost :   0.019\n",
      " 1001 epoch  |    0.316  |    0.917  |    0.901  |  cost :   0.018\n",
      ">>> training time :  7.01240086555481\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "x_data = [\n",
    "    [1., 1., 1., 1., 1.],\n",
    "    [1., 0., 3., 0., 5.],\n",
    "    [0., 2., 0., 4., 0.]\n",
    "]\n",
    "y_data = [1, 2, 3, 4, 5]\n",
    "\n",
    "W = tf.Variable(tf.random.uniform((1,3), -1, 1))\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "for i in range(1000+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = tf.matmul(W, x_data)\n",
    "        cost = tf.reduce_mean(tf.square(tf.subtract(hypothesis, y_data)))\n",
    "        pass\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        print(f'{i+1:5} epoch  |  {W.numpy()[0][0]:7.3f}  |  {W.numpy()[0][1]:7.3f} ',\n",
    "              f'|  {W.numpy()[0][2]:7.3f}  |  cost : {cost.numpy():7.3f}')\n",
    "    \n",
    "    grads = tape.gradient( cost, [W] )\n",
    "    optimizer.apply_gradients(grads_and_vars = zip(grads, [W]))\n",
    "\n",
    "finish = time.time()\n",
    "print('>>> training time : ', finish-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-variable linear regression - Predicting exam score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch | cost\n",
      "    1 | 6876.448\n",
      "  201 |   1.048\n",
      "  401 |   1.041\n",
      "  601 |   1.035\n",
      "  801 |   1.029\n",
      " 1001 |   1.023\n",
      " 1201 |   1.016\n",
      " 1401 |   1.010\n",
      " 1601 |   1.004\n",
      " 1801 |   0.998\n",
      " 2001 |   0.993\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "data = np.array([\n",
    "    # X1,  X2,  X3,  y\n",
    "    [ 73., 80., 75., 152. ],\n",
    "    [ 93.,  88.,  93., 185. ],\n",
    "    [ 89.,  91.,  90., 180. ],\n",
    "    [ 96.,  98., 100., 196. ],\n",
    "    [ 73.,  66.,  70., 142. ]\n",
    "], np.float32)\n",
    "\n",
    "X = data[:, :-1]\n",
    "y = data[:, [-1]]\n",
    "\n",
    "W = tf.Variable( tf.random.uniform((3,1)) )\n",
    "b = tf.Variable( tf.random.uniform((1,)) )\n",
    "\n",
    "learning_rate = 0.000001\n",
    "\n",
    "def predict(X):\n",
    "    return tf.matmul( X, W ) + b\n",
    "\n",
    "print('epoch | cost')\n",
    "for i in range(2000+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost = tf.reduce_mean(tf.square(tf.subtract(predict(X), y)))\n",
    "    \n",
    "    if i%200==0:\n",
    "        print(f'{i+1:5} | {cost:7.3f}')\n",
    "    \n",
    "    # calcuating the gradients of the cost\n",
    "    W_grad, b_grad = tape.gradient( cost, [W, b] )\n",
    "    \n",
    "    # updating the variables/parameters (W, b)\n",
    "    W.assign_sub(learning_rate * W_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6215449 ]\n",
      " [0.52012724]\n",
      " [0.8603387 ]]\n",
      "\n",
      "[0.5595095]\n"
     ]
    }
   ],
   "source": [
    "# weights\n",
    "print(W.numpy())\n",
    "print()\n",
    "print(b.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[152.]\n",
      " [185.]\n",
      " [180.]\n",
      " [196.]\n",
      " [142.]]\n",
      "\n",
      "[[152.06787]\n",
      " [184.14587]\n",
      " [180.63907]\n",
      " [197.23416]\n",
      " [140.48439]]\n"
     ]
    }
   ],
   "source": [
    "print(y)  # labels\n",
    "print()\n",
    "print(predict(X).numpy())  # prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[184.44025],\n",
       "       [173.74979]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict([\n",
    "    [89., 95., 92.],\n",
    "    [84., 92., 85.]\n",
    "]).numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
